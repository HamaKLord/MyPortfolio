import pandas as pd
import string
from nltk.corpus import stopwords
import nltk

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# Load raw datasets
data1 = pd.read_csv('./data/raw/emotion_sentimen_dataset.csv')
data2 = pd.read_csv('./data/raw/test.csv')

# Combine datasets
data = pd.concat([data1, data2], ignore_index=True)

# Drop duplicates and handle missing values
data.drop_duplicates(inplace=True)
data.dropna(subset=['text'], inplace=True)

# Text preprocessing function
def clean_text(text):
    text = text.lower()
    text = "".join([char for char in text if char not in string.punctuation])
    words = text.split()
    words = [word for word in words if word not in stop_words]
    return " ".join(words)

# Apply preprocessing
data['text'] = data['text'].apply(clean_text)

# Save preprocessed data
data.to_csv('./data/processed/mood_data_cleaned.csv', index=False)
print("Data preprocessing complete. Cleaned data saved.")

